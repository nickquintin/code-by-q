from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
 from datetime import datetime, timedelta
import time
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# --- GOOGLE SHEETS SETUP ---
scope = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]
creds = ServiceAccountCredentials.from_json_keyfile_name("/Users/katehandley/Downloads/credentials.json", scope)
client = gspread.authorize(creds)
sheet = client.open_by_key("1IP6xBwC3N3Wa6SnZXMHftBhEY0acWr6UjNwtd4omXIA").sheet1

# --- SELENIUM SETUP ---
chrome_options = Options()
chrome_options.add_argument("--headless")
driver = webdriver.Chrome(options=chrome_options)

# --- CONFIG ---
JOB_QUERY = "Sales Engineer"
LOCATION = "United States"
LINKEDIN_URL = f"https://www.linkedin.com/jobs/search/?keywords={JOB_QUERY}&location={LOCATION}&f_TPR=r86400"  # last 24 hours

# --- SCRAPE JOBS ---
driver.get(LINKEDIN_URL)
time.sleep(5)

jobs = driver.find_elements(By.CLASS_NAME, "base-card")

for job in jobs:
    try:
        title = job.find_element(By.CLASS_NAME, "base-search-card__title").text
        company = job.find_element(By.CLASS_NAME, "base-search-card__subtitle").text
        location = job.find_element(By.CLASS_NAME, "job-search-card__location").text
        date_posted = "Today"
        job_url = job.find_element(By.CLASS_NAME, "base-card__full-link").get_attribute("href")

        # Optional: Visit job_url and scrape full description
        sheet.append_row([title, company, location, date_posted, job_url, ""])

    except Exception as e:
        print("Error:", e)

driver.quit()
